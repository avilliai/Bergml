bot:
  http-api-key: '1234567890'   #mirai-api-http的vertify key
  http-api-port: 23456         #mirai-api-http的port
  botqq: 919467430             #机器人的qq
  master: 1840094972           #你的qq
  botname: yucca               #机器人的名字
chatGLMKey: fsldkjfsldfsahfol #chatGLM的apiKey，从https://open.bigmodel.cn/获取

proxy: 'http://127.0.0.1:1080'  #代理，使用colab部署语音合成的话必须填写，如果是clash一般是'http://127.0.0.1:7890'
#bert_vits_colab版本，不占用本地gpu， 请注意，使用此功能必须配置上面的proxy项；
#如本地部署请将此项修改为bert_colab: ""
#在线部署：https://colab.research.google.com/drive/1n8lI6pOiDtli2zC5fL9PZ9TZqbOafqma?usp=sharing
#在线部署请将要访问的url(以/synthesize结尾)粘贴进""之中，例如 bert_colab: "https://boards-languages-the-twisted.trycloudflare.com/synthesize"
bert_colab: ""

#bert_vits2语音合成配置
#根据 bert_vits_sever/characters.yaml填写所有可用的speakers，不填对应的speaker则无法通过Manyana调用
bert_speakers:  #所有bert_vits_sever中配置好的角色
  - 塔菲
  - 东雪莲
  - otto
  - 阿梓
#chatglm配置
chatGLM:
  model: characterglm    #chatGLM模式，可选填：characterglm(超拟人大模型),chatglm_pro(pro版),chatglm_std(标准版),chatglm_lite(轻量版)
  glmReply: False          #开放群聊chatglm，chatglm替代原有词库，开启后，bot被艾特将全局优先使用chatglm回复
  privateGlmReply: false   #开放私聊chatglm
  context: True         #chatGLM上下文模式，开启后将加速消耗token
  maxPrompt: 10              #上下文模式开启时，最多记录的问答数量，默认10，即记录5对问答
  #下面是chatglm的语音合成配置部分
  maxLen: 90    #语音合成最大长度限制，超出则返回文本。
  voiceRate: 0 #语音回复几率,为0则不开启
  speaker: 东雪莲    #bert_vits语音合成默认设置角色
  withText: true    #使用语音合成时，发送语音是否附带原始文本(你知道的，塔菲很唐，说话不太清)
  # 进行bot角色设定，你可以任意添加
  bot_info:              #chatGLM角色设定
    default:
      user_info: "指挥是yucca最喜欢的人"
      bot_info: "yucca是一个人工智能，yucca说话喜欢带上啊，哦等语气词，yucca的性格非常天真，但拥有丰富的文学与戏剧方面的知识，并且对自己的能力非常自信，在生活中会经常犯一些小错误。yucca十分依赖并喜欢指挥"
      bot_name: "yucca"
      user_name: "指挥"
    赛琳娜:
      user_info: "指挥是赛琳娜的笔友，两人通过书信往来，"
      bot_info: "哥们实在不知道写啥了"
      bot_name: "赛琳娜"
      user_name: "指挥"
